{"cells":[{"cell_type":"markdown","metadata":{"id":"1Sp380kp3QvN"},"source":["# GoogleNet \n","- is equal to Inception v1\n","---\n","\n","**Description**\n","- GoogleNet의 특징:\n","\n","1. GoogleNet Architecture:\n","  <img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FIq9NO%2FbtqyPWk5PBX%2FK2JicGjIjj5w0eFIbhx4bK%2Fimg.png\"> </img><br></br>\n","\n","    - GoogLeNet은 네트워크의 depth와 width를 늘리면서도 내부적으로 Inception Module을 활용해 computational efficiency를 확보함\n","    - 이전에 나온 VGGNet이 깊은 네트워크로 AlexNet보다 높은 성능을 얻었지만, 파라미터 측면에서 효율적이지 못하다는점을 보완하기 위해 만듬 <br></br>\n","\n","2. Things to discuss about issues:\n","   - 네트워크의 성능을 올리는 가장 직접적인 방법은 depth, width같은 size를 증대 할 수 있다 \n","   - 모델의 층이 깊어질수록 성능은 향상 됨 \n","   - 하지만 계산해야 할 연산량이 늘어나 overfitting할 가능성이 증가\n","   - RAM을 너무나 많이 사용해 시간이 오래걸리는 비효율성 발생 <br> </br>\n","\n","3. Solution:\n","   - 적은 연산량을 가지고 효율적으로 모델의 특징을 추출하는 방법 고안 \n","   - Sparse Connection - fully connected 를 sparsely connected architecture로 변경\n","   - Inception Module - 3개의 inception blocks (3a,3b), (4a~4e), (5a,5b), 총 9개의 inception modules \n","   - Auxiliary Classifier - gradient vanishing 문제 해결 위해 2개의 auxiliary classifier 추가,  <br> </br>\n","\n","4. Global Average Pooling(GAP):\n","  <img src=\"https://alexisbcook.github.io/assets/global_average_pooling.png\" width='600px'></img><br></br>\n","   - patch size = 7x7\n","   - stride = 1\n","   - global average pooling은 전 층에서 산출된 특성맵들을 각각 평균냄\n","   - 이후 이어서 1차원 벡터를 만듬\n","   - why? 1차원 벡터로 만들어야만 최종적으로 이미지 분류를 위한 softmax 층을 연결함\n","   - 가장 큰 이유는 finetuning의 용이성을 위함   <br> </br>\n","\n","5. Max Pooling:\n","   - patch size = 3x3\n","   - stride = 2\n","   - number of max pooling = 4  <br> </br>\n","\n","\n","6. Inception Module:\n","   - 1x1 Convolution: kernel_size=1, stride= 1, padding=0\n","   - 3x3 Convolution: kernel_size=3, stride= 1, padding=1\n","   - 5x5 Convolution: kernel_size=5, stride= 1, pading=2\n","   - Max-Pooling: kernel_size=3, stride=1, padding=1 <br> </br>\n","\n","7. Auxiliary Classifier:\n","   - 1x1 convolution output channel =  128 적용 \n","   - dropout rate  = 0.7 적용  \n","   - uxiliary Classifier의 input dimensioin =  aux1(512), aux2(528)  <br> </br>\n","\n","\n","8. Fully Connected Layer(FC Layer): \n","   - 1개의 1024 channel\n","   - Softmax  <br></br>\n","\n","9. Augmentation:\n","   - Input image shape = 224x224x3\n","   - resize = 227x227\n","   - Mean subtraction of RGB per channel <br></br>\n","\n","\n","10. Hyperparameter\n","   - Optimizer = SGD  -> Adam으로 변경\n","   - Momentum = 0.9 \n","   - Batch size = 64  -> 128 변경\n","   - learning rate = learning rate scheduler 사용 -> 0.0001으로 변경 \n","   - Epoch = not mentioned -> 20 적용\n","   - Dropout = 0.4(FC layer) <br></br>\n","\n","11. Dataset\n","    - 논문 : ImageNet Large Scale Visual Recognition Challenge(ILSVRC)-2014\n","    - 구현 : CIFAR-10 <br></br>\n","\n","12. System Environment:\n","    - Google Colab Pro \n","​\n","---\n","\n","**Reference**\n","- https://roytravel.tistory.com/338\n","- https://technical-support.tistory.com/87\n","- https://blog.naver.com/paragonyun/222914679046\n","- https://github.com/paragonyun/Papers_I_must_read/tree/main/GoogLeNet\n","- https://bskyvision.com/entry/CNN-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EB%93%A4-GoogLeNetinception-v1%EC%9D%98-%EA%B5%AC%EC%A1%B0\n","- https://d2l.ai/chapter_convolutional-modern/googlenet.html\n","- https://inhovation97.tistory.com/45?category=920765\n","- https://teddylee777.github.io/python/inception-module\n","- C. Szegedy et al., \"Going deeper with convolutions,\" 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Boston, MA, USA, 2015, pp. 1-9, doi: 10.1109/CVPR.2015.7298594.<br> https://arxiv.org/pdf/1409.4842.pdf\n"]},{"cell_type":"markdown","metadata":{"id":"uvfObps51uiH"},"source":["**Load Modules**"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"hcRdxXMKjegN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676257454354,"user_tz":-540,"elapsed":7970,"user":{"displayName":"이소강","userId":"11303362498691369775"}},"outputId":"ae31eb92-9562-4cb2-b68b-5522668e57f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorboardX in /usr/local/lib/python3.8/dist-packages (2.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n","Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (23.0)\n"]}],"source":["# Utils\n","import numpy as np\n","from tqdm import tqdm \n","import matplotlib.pyplot as plt\n","\n","# Torch\n","import torch\n","import torch.nn as nn\n","from torch import Tensor\n","from typing import Optional\n","import torch.nn.functional as F\n","from torchsummary import summary\n","from torchvision import transforms\n","import torchvision\n","from torch.utils.tensorboard import SummaryWriter\n","! pip install tensorboardX\n","from tensorboardX import SummaryWriter"]},{"cell_type":"markdown","metadata":{"id":"Pl8EPcXi1uiK"},"source":["**Set Hyperparameters**"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"aYFRBdKhuF1z","executionInfo":{"status":"ok","timestamp":1676257454355,"user_tz":-540,"elapsed":9,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"outputs":[],"source":["batch_size = 128\n","num_epochs = 20\n","learning_rate = 0.0001"]},{"cell_type":"markdown","metadata":{"id":"qQNTtPvx1uiL"},"source":["**Load Data**\n","- CIFAR10"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EL5Z5GNPuJ3_","outputId":"2fb3acf7-94bc-49cd-a01c-b8cb72b77d86","executionInfo":{"status":"ok","timestamp":1676257456568,"user_tz":-540,"elapsed":2221,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["train_set = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transforms.ToTensor())\n","test_set = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transforms.ToTensor())"]},{"cell_type":"markdown","metadata":{"id":"7F7mpRqp1uiM"},"source":["**Mean subtraction of RGB per channel**"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gddlN1UluOxW","outputId":"ba361bd4-2b97-4b62-9a39-fb0389ae889e","executionInfo":{"status":"ok","timestamp":1676257487242,"user_tz":-540,"elapsed":30677,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0.49139965 0.48215845 0.4465309\n","0.20220213 0.19931543 0.20086348\n"]}],"source":["train_meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x, _ in train_set]\n","train_stdRGB = [np.std(x.numpy(), axis=(1,2)) for x, _ in train_set]\n","\n","train_meanR = np.mean([m[0] for m in train_meanRGB])\n","train_meanG = np.mean([m[1] for m in train_meanRGB])\n","train_meanB = np.mean([m[2] for m in train_meanRGB])\n","train_stdR = np.mean([s[0] for s in train_stdRGB])\n","train_stdG = np.mean([s[1] for s in train_stdRGB])\n","train_stdB = np.mean([s[2] for s in train_stdRGB])\n","\n","print(train_meanR, train_meanG, train_meanB)\n","print(train_stdR, train_stdG, train_stdB)"]},{"cell_type":"markdown","metadata":{"id":"mSyibD2q1uiN"},"source":["**Image Preprocessing**\n","- resize the image\n","- normalize by RGB channel (mean, STD) "]},{"cell_type":"code","execution_count":5,"metadata":{"id":"fmXi7T7hukJd","executionInfo":{"status":"ok","timestamp":1676257487242,"user_tz":-540,"elapsed":17,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"outputs":[],"source":["train_transformer = transforms.Compose([transforms.Resize((224,224)),\n","                                        transforms.ToTensor(),\n","                                        transforms.Normalize(mean=[train_meanR, train_meanG, train_meanB], std=[train_stdR, train_stdG, train_stdB])])\n","\n","train_set.transform = train_transformer\n","test_set.transform = train_transformer"]},{"cell_type":"markdown","metadata":{"id":"l9F3aG-E1uiO"},"source":["**Define DataLoader**"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"r807IlH0unvG","executionInfo":{"status":"ok","timestamp":1676257487243,"user_tz":-540,"elapsed":16,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"outputs":[],"source":["trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n","testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=2)"]},{"cell_type":"markdown","metadata":{"id":"OmOEnqn91uiP"},"source":["**Created GoogleNet Model**\n","- Convolutional Block\n","- Inception Modules\n","- Auxiliary classifier"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"CCKjZdRYt_8-","executionInfo":{"status":"ok","timestamp":1676257487243,"user_tz":-540,"elapsed":16,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"outputs":[],"source":["class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, **kwargs):\n","        super(ConvBlock, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n","        self.batchnorm = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.batchnorm(x)\n","        x = self.relu(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"xUadKelpjegO","executionInfo":{"status":"ok","timestamp":1676257487244,"user_tz":-540,"elapsed":16,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"outputs":[],"source":["class Inception(nn.Module):\n","    def __init__(self, in_channels, n1, n3_reduce, n3, n5_reduce, n5, pool_proj):\n","        super().__init__()\n","        self.branch1 = ConvBlock(in_channels, n1, kernel_size=1, stride=1, padding=0)\n","\n","        self.branch2 = nn.Sequential(\n","          ConvBlock(in_channels, n3_reduce, kernel_size=1, stride=1, padding=0),\n","          ConvBlock(n3_reduce, n3, kernel_size=3, stride=1, padding=1)\n","        )\n","        \n","        self.branch3 = nn.Sequential(\n","          ConvBlock(in_channels, n5_reduce, kernel_size=1, stride=1, padding=0),\n","          ConvBlock(n5_reduce, n5, kernel_size=5, stride=1, padding=2)\n","        )\n","\n","        self.branch4 = nn.Sequential(\n","          nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n","          ConvBlock(in_channels, pool_proj, kernel_size=1, stride=1, padding=0)\n","        )\n","        \n","    def forward(self, x):\n","        x1 = self.branch1(x)\n","        x2 = self.branch2(x)\n","        x3 = self.branch3(x)\n","        x4 = self.branch4(x)\n","\n","        return torch.cat([x1, x2, x3, x4], dim=1)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"khTaozdHjegP","executionInfo":{"status":"ok","timestamp":1676257487244,"user_tz":-540,"elapsed":16,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"outputs":[],"source":["class InceptionAux(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super().__init__()\n","        self.avg_conv = nn.Sequential(\n","          nn.AvgPool2d(kernel_size=5, stride=3),\n","          ConvBlock(in_channels, 128, kernel_size=1, stride=1, padding=0)\n","        )\n","\n","        self.fc = nn.Sequential(\n","          nn.Linear(2048, 1024),\n","          nn.ReLU(),\n","          nn.Dropout(p=0.7),\n","          nn.Linear(1024, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.avg_conv(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"wrk2R3NMjegQ","executionInfo":{"status":"ok","timestamp":1676258359522,"user_tz":-540,"elapsed":538,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"outputs":[],"source":["class GoogLeNet(nn.Module):\n","    def __init__(self, aux_logits=True, num_classes=10):\n","        super().__init__()\n","\n","        self.aux_logits = aux_logits\n","\n","        self.conv1 = ConvBlock(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n","        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=False)\n","        self.conv2 = ConvBlock(in_channels=64, out_channels=64, kernel_size=1, stride=1, padding=0)\n","        self.conv3 = ConvBlock(in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=1)\n","        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n","        self.a3 = Inception(192, 64, 96, 128, 16, 32, 32)\n","        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)\n","        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=False)\n","        self.a4 = Inception(480, 192, 96, 208, 16, 48, 64)\n","        self.b4 = Inception(512, 160, 112, 224, 24, 64, 64)\n","        self.c4 = Inception(512, 128, 128, 256, 24, 64, 64)\n","        self.d4 = Inception(512, 112, 144, 288, 32, 64, 64)\n","        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n","        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n","        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n","        self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n","        self.dropout = nn.Dropout(p=0.4)\n","        self.linear = nn.Linear(1024, num_classes)\n","\n","        if self.aux_logits:\n","            self.aux1 = InceptionAux(512, num_classes)\n","            self.aux2 = InceptionAux(528, num_classes)\n","        else:\n","            self.aux1 = None\n","            self.aux2 = None\n","        \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        # print('conv1 :',x.shape)\n","        x = self.maxpool1(x)\n","        # print('maxpool1 :',x.shape)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        # print('conv3 :',x.shape)\n","        x = self.maxpool2(x)\n","        # print('maxpool2 :',x.shape)\n","        x = self.a3(x)\n","        # print('a3 :',x.shape)\n","        x = self.b3(x)\n","        # print('b3 :',x.shape)\n","        x = self.maxpool3(x)\n","        # print('maxpool3 :',x.shape)\n","        x = self.a4(x)\n","        # print('a4 :',x.shape)\n","        \n","        aux1 = None\n","        if self.aux_logits and self.training:\n","            aux1 = self.aux1(x)\n","\n","        x = self.b4(x)\n","        # print('10 :',x.shape)\n","        x = self.c4(x)\n","        # print('11 :',x.shape)\n","        x = self.d4(x)\n","        # print('12 :',x.shape)\n","        \n","        aux2 = None\n","        if self.aux_logits and self.training:\n","            aux2 = self.aux2(x)\n","\n","        x = self.e4(x)\n","        # print(x.shape)\n","        x = self.maxpool4(x)\n","        # print(x.shape)\n","        x = self.a5(x)\n","        # print(x.shape)\n","        x = self.b5(x)\n","        # print(x.shape)\n","        x = self.avgpool(x)\n","        # print(x.shape)\n","        x = x.view(x.shape[0], -1)\n","        x = self.linear(x)\n","        x = self.dropout(x)\n","\n","        if self.aux_logits and self.training:\n","            return [x, aux1, aux2]\n","        else:\n","            return x"]},{"cell_type":"markdown","metadata":{"id":"u4JYoRTW1uiS"},"source":["**Set Device and Check Summary**"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ApyiF7v_jegR","outputId":"3bd484bb-7dc6-4e1d-c164-62b6f062bc68","executionInfo":{"status":"ok","timestamp":1676258360056,"user_tz":-540,"elapsed":537,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["use_cuda :  True\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,472\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         ConvBlock-4         [-1, 64, 112, 112]               0\n","         MaxPool2d-5           [-1, 64, 56, 56]               0\n","            Conv2d-6           [-1, 64, 56, 56]           4,160\n","       BatchNorm2d-7           [-1, 64, 56, 56]             128\n","              ReLU-8           [-1, 64, 56, 56]               0\n","         ConvBlock-9           [-1, 64, 56, 56]               0\n","           Conv2d-10          [-1, 192, 56, 56]         110,784\n","      BatchNorm2d-11          [-1, 192, 56, 56]             384\n","             ReLU-12          [-1, 192, 56, 56]               0\n","        ConvBlock-13          [-1, 192, 56, 56]               0\n","        MaxPool2d-14          [-1, 192, 28, 28]               0\n","           Conv2d-15           [-1, 64, 28, 28]          12,352\n","      BatchNorm2d-16           [-1, 64, 28, 28]             128\n","             ReLU-17           [-1, 64, 28, 28]               0\n","        ConvBlock-18           [-1, 64, 28, 28]               0\n","           Conv2d-19           [-1, 96, 28, 28]          18,528\n","      BatchNorm2d-20           [-1, 96, 28, 28]             192\n","             ReLU-21           [-1, 96, 28, 28]               0\n","        ConvBlock-22           [-1, 96, 28, 28]               0\n","           Conv2d-23          [-1, 128, 28, 28]         110,720\n","      BatchNorm2d-24          [-1, 128, 28, 28]             256\n","             ReLU-25          [-1, 128, 28, 28]               0\n","        ConvBlock-26          [-1, 128, 28, 28]               0\n","           Conv2d-27           [-1, 16, 28, 28]           3,088\n","      BatchNorm2d-28           [-1, 16, 28, 28]              32\n","             ReLU-29           [-1, 16, 28, 28]               0\n","        ConvBlock-30           [-1, 16, 28, 28]               0\n","           Conv2d-31           [-1, 32, 28, 28]          12,832\n","      BatchNorm2d-32           [-1, 32, 28, 28]              64\n","             ReLU-33           [-1, 32, 28, 28]               0\n","        ConvBlock-34           [-1, 32, 28, 28]               0\n","        MaxPool2d-35          [-1, 192, 28, 28]               0\n","           Conv2d-36           [-1, 32, 28, 28]           6,176\n","      BatchNorm2d-37           [-1, 32, 28, 28]              64\n","             ReLU-38           [-1, 32, 28, 28]               0\n","        ConvBlock-39           [-1, 32, 28, 28]               0\n","        Inception-40          [-1, 256, 28, 28]               0\n","           Conv2d-41          [-1, 128, 28, 28]          32,896\n","      BatchNorm2d-42          [-1, 128, 28, 28]             256\n","             ReLU-43          [-1, 128, 28, 28]               0\n","        ConvBlock-44          [-1, 128, 28, 28]               0\n","           Conv2d-45          [-1, 128, 28, 28]          32,896\n","      BatchNorm2d-46          [-1, 128, 28, 28]             256\n","             ReLU-47          [-1, 128, 28, 28]               0\n","        ConvBlock-48          [-1, 128, 28, 28]               0\n","           Conv2d-49          [-1, 192, 28, 28]         221,376\n","      BatchNorm2d-50          [-1, 192, 28, 28]             384\n","             ReLU-51          [-1, 192, 28, 28]               0\n","        ConvBlock-52          [-1, 192, 28, 28]               0\n","           Conv2d-53           [-1, 32, 28, 28]           8,224\n","      BatchNorm2d-54           [-1, 32, 28, 28]              64\n","             ReLU-55           [-1, 32, 28, 28]               0\n","        ConvBlock-56           [-1, 32, 28, 28]               0\n","           Conv2d-57           [-1, 96, 28, 28]          76,896\n","      BatchNorm2d-58           [-1, 96, 28, 28]             192\n","             ReLU-59           [-1, 96, 28, 28]               0\n","        ConvBlock-60           [-1, 96, 28, 28]               0\n","        MaxPool2d-61          [-1, 256, 28, 28]               0\n","           Conv2d-62           [-1, 64, 28, 28]          16,448\n","      BatchNorm2d-63           [-1, 64, 28, 28]             128\n","             ReLU-64           [-1, 64, 28, 28]               0\n","        ConvBlock-65           [-1, 64, 28, 28]               0\n","        Inception-66          [-1, 480, 28, 28]               0\n","        MaxPool2d-67          [-1, 480, 14, 14]               0\n","           Conv2d-68          [-1, 192, 14, 14]          92,352\n","      BatchNorm2d-69          [-1, 192, 14, 14]             384\n","             ReLU-70          [-1, 192, 14, 14]               0\n","        ConvBlock-71          [-1, 192, 14, 14]               0\n","           Conv2d-72           [-1, 96, 14, 14]          46,176\n","      BatchNorm2d-73           [-1, 96, 14, 14]             192\n","             ReLU-74           [-1, 96, 14, 14]               0\n","        ConvBlock-75           [-1, 96, 14, 14]               0\n","           Conv2d-76          [-1, 208, 14, 14]         179,920\n","      BatchNorm2d-77          [-1, 208, 14, 14]             416\n","             ReLU-78          [-1, 208, 14, 14]               0\n","        ConvBlock-79          [-1, 208, 14, 14]               0\n","           Conv2d-80           [-1, 16, 14, 14]           7,696\n","      BatchNorm2d-81           [-1, 16, 14, 14]              32\n","             ReLU-82           [-1, 16, 14, 14]               0\n","        ConvBlock-83           [-1, 16, 14, 14]               0\n","           Conv2d-84           [-1, 48, 14, 14]          19,248\n","      BatchNorm2d-85           [-1, 48, 14, 14]              96\n","             ReLU-86           [-1, 48, 14, 14]               0\n","        ConvBlock-87           [-1, 48, 14, 14]               0\n","        MaxPool2d-88          [-1, 480, 14, 14]               0\n","           Conv2d-89           [-1, 64, 14, 14]          30,784\n","      BatchNorm2d-90           [-1, 64, 14, 14]             128\n","             ReLU-91           [-1, 64, 14, 14]               0\n","        ConvBlock-92           [-1, 64, 14, 14]               0\n","        Inception-93          [-1, 512, 14, 14]               0\n","        AvgPool2d-94            [-1, 512, 4, 4]               0\n","           Conv2d-95            [-1, 128, 4, 4]          65,664\n","      BatchNorm2d-96            [-1, 128, 4, 4]             256\n","             ReLU-97            [-1, 128, 4, 4]               0\n","        ConvBlock-98            [-1, 128, 4, 4]               0\n","           Linear-99                 [-1, 1024]       2,098,176\n","            ReLU-100                 [-1, 1024]               0\n","         Dropout-101                 [-1, 1024]               0\n","          Linear-102                   [-1, 10]          10,250\n","    InceptionAux-103                   [-1, 10]               0\n","          Conv2d-104          [-1, 160, 14, 14]          82,080\n","     BatchNorm2d-105          [-1, 160, 14, 14]             320\n","            ReLU-106          [-1, 160, 14, 14]               0\n","       ConvBlock-107          [-1, 160, 14, 14]               0\n","          Conv2d-108          [-1, 112, 14, 14]          57,456\n","     BatchNorm2d-109          [-1, 112, 14, 14]             224\n","            ReLU-110          [-1, 112, 14, 14]               0\n","       ConvBlock-111          [-1, 112, 14, 14]               0\n","          Conv2d-112          [-1, 224, 14, 14]         226,016\n","     BatchNorm2d-113          [-1, 224, 14, 14]             448\n","            ReLU-114          [-1, 224, 14, 14]               0\n","       ConvBlock-115          [-1, 224, 14, 14]               0\n","          Conv2d-116           [-1, 24, 14, 14]          12,312\n","     BatchNorm2d-117           [-1, 24, 14, 14]              48\n","            ReLU-118           [-1, 24, 14, 14]               0\n","       ConvBlock-119           [-1, 24, 14, 14]               0\n","          Conv2d-120           [-1, 64, 14, 14]          38,464\n","     BatchNorm2d-121           [-1, 64, 14, 14]             128\n","            ReLU-122           [-1, 64, 14, 14]               0\n","       ConvBlock-123           [-1, 64, 14, 14]               0\n","       MaxPool2d-124          [-1, 512, 14, 14]               0\n","          Conv2d-125           [-1, 64, 14, 14]          32,832\n","     BatchNorm2d-126           [-1, 64, 14, 14]             128\n","            ReLU-127           [-1, 64, 14, 14]               0\n","       ConvBlock-128           [-1, 64, 14, 14]               0\n","       Inception-129          [-1, 512, 14, 14]               0\n","          Conv2d-130          [-1, 128, 14, 14]          65,664\n","     BatchNorm2d-131          [-1, 128, 14, 14]             256\n","            ReLU-132          [-1, 128, 14, 14]               0\n","       ConvBlock-133          [-1, 128, 14, 14]               0\n","          Conv2d-134          [-1, 128, 14, 14]          65,664\n","     BatchNorm2d-135          [-1, 128, 14, 14]             256\n","            ReLU-136          [-1, 128, 14, 14]               0\n","       ConvBlock-137          [-1, 128, 14, 14]               0\n","          Conv2d-138          [-1, 256, 14, 14]         295,168\n","     BatchNorm2d-139          [-1, 256, 14, 14]             512\n","            ReLU-140          [-1, 256, 14, 14]               0\n","       ConvBlock-141          [-1, 256, 14, 14]               0\n","          Conv2d-142           [-1, 24, 14, 14]          12,312\n","     BatchNorm2d-143           [-1, 24, 14, 14]              48\n","            ReLU-144           [-1, 24, 14, 14]               0\n","       ConvBlock-145           [-1, 24, 14, 14]               0\n","          Conv2d-146           [-1, 64, 14, 14]          38,464\n","     BatchNorm2d-147           [-1, 64, 14, 14]             128\n","            ReLU-148           [-1, 64, 14, 14]               0\n","       ConvBlock-149           [-1, 64, 14, 14]               0\n","       MaxPool2d-150          [-1, 512, 14, 14]               0\n","          Conv2d-151           [-1, 64, 14, 14]          32,832\n","     BatchNorm2d-152           [-1, 64, 14, 14]             128\n","            ReLU-153           [-1, 64, 14, 14]               0\n","       ConvBlock-154           [-1, 64, 14, 14]               0\n","       Inception-155          [-1, 512, 14, 14]               0\n","          Conv2d-156          [-1, 112, 14, 14]          57,456\n","     BatchNorm2d-157          [-1, 112, 14, 14]             224\n","            ReLU-158          [-1, 112, 14, 14]               0\n","       ConvBlock-159          [-1, 112, 14, 14]               0\n","          Conv2d-160          [-1, 144, 14, 14]          73,872\n","     BatchNorm2d-161          [-1, 144, 14, 14]             288\n","            ReLU-162          [-1, 144, 14, 14]               0\n","       ConvBlock-163          [-1, 144, 14, 14]               0\n","          Conv2d-164          [-1, 288, 14, 14]         373,536\n","     BatchNorm2d-165          [-1, 288, 14, 14]             576\n","            ReLU-166          [-1, 288, 14, 14]               0\n","       ConvBlock-167          [-1, 288, 14, 14]               0\n","          Conv2d-168           [-1, 32, 14, 14]          16,416\n","     BatchNorm2d-169           [-1, 32, 14, 14]              64\n","            ReLU-170           [-1, 32, 14, 14]               0\n","       ConvBlock-171           [-1, 32, 14, 14]               0\n","          Conv2d-172           [-1, 64, 14, 14]          51,264\n","     BatchNorm2d-173           [-1, 64, 14, 14]             128\n","            ReLU-174           [-1, 64, 14, 14]               0\n","       ConvBlock-175           [-1, 64, 14, 14]               0\n","       MaxPool2d-176          [-1, 512, 14, 14]               0\n","          Conv2d-177           [-1, 64, 14, 14]          32,832\n","     BatchNorm2d-178           [-1, 64, 14, 14]             128\n","            ReLU-179           [-1, 64, 14, 14]               0\n","       ConvBlock-180           [-1, 64, 14, 14]               0\n","       Inception-181          [-1, 528, 14, 14]               0\n","       AvgPool2d-182            [-1, 528, 4, 4]               0\n","          Conv2d-183            [-1, 128, 4, 4]          67,712\n","     BatchNorm2d-184            [-1, 128, 4, 4]             256\n","            ReLU-185            [-1, 128, 4, 4]               0\n","       ConvBlock-186            [-1, 128, 4, 4]               0\n","          Linear-187                 [-1, 1024]       2,098,176\n","            ReLU-188                 [-1, 1024]               0\n","         Dropout-189                 [-1, 1024]               0\n","          Linear-190                   [-1, 10]          10,250\n","    InceptionAux-191                   [-1, 10]               0\n","          Conv2d-192          [-1, 256, 14, 14]         135,424\n","     BatchNorm2d-193          [-1, 256, 14, 14]             512\n","            ReLU-194          [-1, 256, 14, 14]               0\n","       ConvBlock-195          [-1, 256, 14, 14]               0\n","          Conv2d-196          [-1, 160, 14, 14]          84,640\n","     BatchNorm2d-197          [-1, 160, 14, 14]             320\n","            ReLU-198          [-1, 160, 14, 14]               0\n","       ConvBlock-199          [-1, 160, 14, 14]               0\n","          Conv2d-200          [-1, 320, 14, 14]         461,120\n","     BatchNorm2d-201          [-1, 320, 14, 14]             640\n","            ReLU-202          [-1, 320, 14, 14]               0\n","       ConvBlock-203          [-1, 320, 14, 14]               0\n","          Conv2d-204           [-1, 32, 14, 14]          16,928\n","     BatchNorm2d-205           [-1, 32, 14, 14]              64\n","            ReLU-206           [-1, 32, 14, 14]               0\n","       ConvBlock-207           [-1, 32, 14, 14]               0\n","          Conv2d-208          [-1, 128, 14, 14]         102,528\n","     BatchNorm2d-209          [-1, 128, 14, 14]             256\n","            ReLU-210          [-1, 128, 14, 14]               0\n","       ConvBlock-211          [-1, 128, 14, 14]               0\n","       MaxPool2d-212          [-1, 528, 14, 14]               0\n","          Conv2d-213          [-1, 128, 14, 14]          67,712\n","     BatchNorm2d-214          [-1, 128, 14, 14]             256\n","            ReLU-215          [-1, 128, 14, 14]               0\n","       ConvBlock-216          [-1, 128, 14, 14]               0\n","       Inception-217          [-1, 832, 14, 14]               0\n","       MaxPool2d-218            [-1, 832, 7, 7]               0\n","          Conv2d-219            [-1, 256, 7, 7]         213,248\n","     BatchNorm2d-220            [-1, 256, 7, 7]             512\n","            ReLU-221            [-1, 256, 7, 7]               0\n","       ConvBlock-222            [-1, 256, 7, 7]               0\n","          Conv2d-223            [-1, 160, 7, 7]         133,280\n","     BatchNorm2d-224            [-1, 160, 7, 7]             320\n","            ReLU-225            [-1, 160, 7, 7]               0\n","       ConvBlock-226            [-1, 160, 7, 7]               0\n","          Conv2d-227            [-1, 320, 7, 7]         461,120\n","     BatchNorm2d-228            [-1, 320, 7, 7]             640\n","            ReLU-229            [-1, 320, 7, 7]               0\n","       ConvBlock-230            [-1, 320, 7, 7]               0\n","          Conv2d-231             [-1, 32, 7, 7]          26,656\n","     BatchNorm2d-232             [-1, 32, 7, 7]              64\n","            ReLU-233             [-1, 32, 7, 7]               0\n","       ConvBlock-234             [-1, 32, 7, 7]               0\n","          Conv2d-235            [-1, 128, 7, 7]         102,528\n","     BatchNorm2d-236            [-1, 128, 7, 7]             256\n","            ReLU-237            [-1, 128, 7, 7]               0\n","       ConvBlock-238            [-1, 128, 7, 7]               0\n","       MaxPool2d-239            [-1, 832, 7, 7]               0\n","          Conv2d-240            [-1, 128, 7, 7]         106,624\n","     BatchNorm2d-241            [-1, 128, 7, 7]             256\n","            ReLU-242            [-1, 128, 7, 7]               0\n","       ConvBlock-243            [-1, 128, 7, 7]               0\n","       Inception-244            [-1, 832, 7, 7]               0\n","          Conv2d-245            [-1, 384, 7, 7]         319,872\n","     BatchNorm2d-246            [-1, 384, 7, 7]             768\n","            ReLU-247            [-1, 384, 7, 7]               0\n","       ConvBlock-248            [-1, 384, 7, 7]               0\n","          Conv2d-249            [-1, 192, 7, 7]         159,936\n","     BatchNorm2d-250            [-1, 192, 7, 7]             384\n","            ReLU-251            [-1, 192, 7, 7]               0\n","       ConvBlock-252            [-1, 192, 7, 7]               0\n","          Conv2d-253            [-1, 384, 7, 7]         663,936\n","     BatchNorm2d-254            [-1, 384, 7, 7]             768\n","            ReLU-255            [-1, 384, 7, 7]               0\n","       ConvBlock-256            [-1, 384, 7, 7]               0\n","          Conv2d-257             [-1, 48, 7, 7]          39,984\n","     BatchNorm2d-258             [-1, 48, 7, 7]              96\n","            ReLU-259             [-1, 48, 7, 7]               0\n","       ConvBlock-260             [-1, 48, 7, 7]               0\n","          Conv2d-261            [-1, 128, 7, 7]         153,728\n","     BatchNorm2d-262            [-1, 128, 7, 7]             256\n","            ReLU-263            [-1, 128, 7, 7]               0\n","       ConvBlock-264            [-1, 128, 7, 7]               0\n","       MaxPool2d-265            [-1, 832, 7, 7]               0\n","          Conv2d-266            [-1, 128, 7, 7]         106,624\n","     BatchNorm2d-267            [-1, 128, 7, 7]             256\n","            ReLU-268            [-1, 128, 7, 7]               0\n","       ConvBlock-269            [-1, 128, 7, 7]               0\n","       Inception-270           [-1, 1024, 7, 7]               0\n","       AvgPool2d-271           [-1, 1024, 1, 1]               0\n","          Linear-272                   [-1, 10]          10,250\n","         Dropout-273                   [-1, 10]               0\n","================================================================\n","Total params: 10,349,102\n","Trainable params: 10,349,102\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 119.00\n","Params size (MB): 39.48\n","Estimated Total Size (MB): 159.06\n","----------------------------------------------------------------\n","None\n"]}],"source":["use_cuda = torch.cuda.is_available()\n","print(\"use_cuda : \", use_cuda)\n","\n","FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n","device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n","\n","net = GoogLeNet().to(device)\n","\n","X = torch.randn(size=(3,224,224)).type(FloatTensor)\n","print(summary(net, (3,224,224)))"]},{"cell_type":"markdown","metadata":{"id":"gv8vFX-Z1uiU"},"source":["**Loss and Optimizer**"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"Rj7pC6pK8Vid","executionInfo":{"status":"ok","timestamp":1676258360498,"user_tz":-540,"elapsed":449,"user":{"displayName":"이소강","userId":"11303362498691369775"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a1776e7f-49c6-47b6-ef68-09692921c539"},"outputs":[{"output_type":"stream","name":"stdout","text":["use_cuda :  True\n"]}],"source":["use_cuda = torch.cuda.is_available()\n","print(\"use_cuda : \", use_cuda)\n","device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n","model = GoogLeNet().to(device)\n","criterion = F.cross_entropy\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"aPNW2lCo1uiU"},"source":["**Training Loop**"]},{"cell_type":"code","source":["writer = SummaryWriter(\"./googlenet/tensorboard\") "],"metadata":{"id":"-9LVolNp5Ea5","executionInfo":{"status":"ok","timestamp":1676258363603,"user_tz":-540,"elapsed":352,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","execution_count":30,"metadata":{"id":"V9Z2kB9YjegS","executionInfo":{"status":"ok","timestamp":1676258364331,"user_tz":-540,"elapsed":2,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"outputs":[],"source":["writer = SummaryWriter(\"./googlenet/tensorboard\") \n","\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data,target) in enumerate(train_loader):\n","        target = target.type(torch.LongTensor)\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        if model.aux_logits:\n","          loss0 = criterion(output[0], target)\n","          loss1 = criterion(output[1], target)\n","          loss2 = criterion(output[2], target)\n","          loss = loss0 + (0.3 * loss1) + (0.3 * loss2)\n","        else:\n","          loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 30 == 0:\n","            print(f\"{batch_idx*len(data)}/{len(train_loader.dataset)}\")\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += criterion(output, target, reduction='mean').item()\n","            writer.add_scalar(\"Test Loss\", test_loss, epoch)\n","            pred = output.argmax(1)\n","            correct += float((pred == target).sum())\n","            writer.add_scalar(\"Test Accuracy\", correct, epoch)\n","            \n","        test_loss /= len(test_loader.dataset)\n","        correct /= len(test_loader.dataset)\n","        return test_loss, correct\n","        writer.close()"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"PE-S-pn8jegS","executionInfo":{"status":"ok","timestamp":1676258366281,"user_tz":-540,"elapsed":345,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"outputs":[],"source":["def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += criterion(output, target, reduction='mean').item()\n","            writer.add_scalar(\"Test Loss\", test_loss, epoch)\n","            pred = output.argmax(1)\n","            correct += float((pred == target).sum())\n","            writer.add_scalar(\"Test Accuracy\", correct, epoch)\n","            \n","        test_loss /= len(test_loader.dataset)\n","        correct /= len(test_loader.dataset)\n","        return test_loss, correct\n","        writer.close()"]},{"cell_type":"markdown","metadata":{"id":"CFPvIKSu1uiV"},"source":["**Per-Epoch Activity**"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"8qKh2uVKjegS","outputId":"4d7ffa19-4a22-46a6-c263-96727dce5db6","executionInfo":{"status":"error","timestamp":1676263239844,"user_tz":-540,"elapsed":4872005,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/20 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▌         | 1/20 [04:06<1:17:58, 246.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 1   Loss : 0.009765417313575745   Accuracy : 0.5817\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 2/20 [08:12<1:13:53, 246.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 2   Loss : 0.007506786978244782   Accuracy : 0.6858\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▌        | 3/20 [12:17<1:09:38, 245.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 3   Loss : 0.006216937685012818   Accuracy : 0.7383\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 4/20 [16:23<1:05:33, 245.82s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 4   Loss : 0.005222002387046814   Accuracy : 0.7867\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 5/20 [20:29<1:01:28, 245.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 5   Loss : 0.005073370137810707   Accuracy : 0.7857\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 6/20 [24:34<57:17, 245.51s/it]  "]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 6   Loss : 0.004707139876484871   Accuracy : 0.8005\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▌      | 7/20 [28:39<53:10, 245.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 7   Loss : 0.0049813461154699324   Accuracy : 0.7851\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 8/20 [32:46<49:09, 245.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 8   Loss : 0.004371858349442482   Accuracy : 0.8128\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▌     | 9/20 [36:51<45:01, 245.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 9   Loss : 0.005029501992464065   Accuracy : 0.808\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 10/20 [40:56<40:53, 245.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 10   Loss : 0.004476995795965195   Accuracy : 0.8247\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▌    | 11/20 [45:02<36:50, 245.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 11   Loss : 0.0051137009888887405   Accuracy : 0.8112\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 12/20 [49:07<32:44, 245.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 12   Loss : 0.0052538052380084995   Accuracy : 0.8155\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▌   | 13/20 [53:13<28:38, 245.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 13   Loss : 0.0050732474088668825   Accuracy : 0.821\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 14/20 [57:18<24:31, 245.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 14   Loss : 0.005561155843734741   Accuracy : 0.8167\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 15/20 [1:01:23<20:27, 245.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 15   Loss : 0.006352495853602886   Accuracy : 0.7953\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 16/20 [1:05:28<16:21, 245.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 16   Loss : 0.004577156454324723   Accuracy : 0.8451\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▌ | 17/20 [1:09:33<12:15, 245.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 17   Loss : 0.005088780882954598   Accuracy : 0.8345\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 18/20 [1:13:38<08:10, 245.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 18   Loss : 0.006354241669178009   Accuracy : 0.805\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n","46080/50000\n","31200/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 19/20 [1:17:44<04:05, 245.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Processing Result = Epoch : 19   Loss : 0.005421359175443649   Accuracy : 0.8349\n","0/50000\n","3840/50000\n","7680/50000\n","11520/50000\n","15360/50000\n","19200/50000\n","23040/50000\n","26880/50000\n","30720/50000\n","34560/50000\n","38400/50000\n","42240/50000\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 19/20 [1:21:11<04:16, 256.39s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-dea27d7134f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-30-d854753be7b0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m30\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for epoch in tqdm(range(1, num_epochs + 1)):\n","    train(model, device, trainloader, optimizer, epoch)\n","    test_loss, test_accuracy = test(model, device, testloader)\n","    writer.add_scalar(\"Test Loss\", test_loss, epoch)\n","    writer.add_scalar(\"Test Accuracy\", test_accuracy, epoch)\n","    print(f\"Processing Result = Epoch : {epoch}   Loss : {test_loss}   Accuracy : {test_accuracy}\")\n","    writer.close()"]},{"cell_type":"markdown","metadata":{"id":"qlZiLqfBwbvx"},"source":["**Result**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g9C2Oh0hwfiU","executionInfo":{"status":"aborted","timestamp":1676258251421,"user_tz":-540,"elapsed":13,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"outputs":[],"source":["print(f\" Result of GoogleNet = Epoch : {epoch}   Loss : {test_loss}   Accuracy : {test_accuracy}\")"]},{"cell_type":"markdown","source":["**Visualization**\n","- Visualize result of Loss and Accuracy by Tensorboard"],"metadata":{"id":"c8Njh9de5lwb"}},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir=./googlenet/tensorboard --port=6006"],"metadata":{"id":"pG5mK9tw5oO7","executionInfo":{"status":"aborted","timestamp":1676258251422,"user_tz":-540,"elapsed":13,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8vxn17wOuwGf","executionInfo":{"status":"aborted","timestamp":1676258251423,"user_tz":-540,"elapsed":14,"user":{"displayName":"이소강","userId":"11303362498691369775"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"1fa24f92b28a3ec6f7f8c10b899db1441c6af89cb002efb1bb768901a2ca3010"}}},"nbformat":4,"nbformat_minor":0}